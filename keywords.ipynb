{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keywords Clustersting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:129: SyntaxWarning: invalid escape sequence '\\g'\n",
      "<>:129: SyntaxWarning: invalid escape sequence '\\g'\n",
      "C:\\Users\\d.tanubudhi\\AppData\\Local\\Temp\\ipykernel_20080\\2687941491.py:129: SyntaxWarning: invalid escape sequence '\\g'\n",
      "  file_path = \"C:\\google_scraping\\Data\\Copy of Enzymedica - Keyword Clustering & Relevancy Definition.xlsx\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping sheet 'README FIRST' - 'Keywords' column missing\n",
      "Skipping sheet 'Sample KW table' - 'Keywords' column missing\n",
      "Skipping sheet 'Sample SQP' - 'Keywords' column missing\n",
      "Skipping sheet 'Relevancy Map' - 'Keywords' column missing\n",
      "Skipping sheet 'ASIN Table' - 'Keywords' column missing\n",
      "Cleaned and clustered keywords saved to clustered_keywords.xlsx\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from fuzzywuzzy import fuzz\n",
    "import spacy\n",
    "\n",
    "# Loading the Spacy Languages\n",
    "nlp_models = {\n",
    "    \"US\": spacy.load(\"en_core_web_sm\"),\n",
    "    \"ES\": spacy.load('es_core_news_sm'),\n",
    "    \"GE\": spacy.load('de_core_news_sm'),\n",
    "    \"FR\": spacy.load(\"fr_core_news_sm\"),\n",
    "    \"IT\": spacy.load('it_core_news_sm')\n",
    "}\n",
    "\n",
    "def preprocess_text(text, market):\n",
    "    \"\"\"\n",
    "    Preprocess the text using language-specific spaCy models for lemmatization and stop-word removal.\n",
    "    \"\"\"\n",
    "    if pd.isna(text) or not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    doc = nlp_models[market](text.lower())\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_stop and token.is_alpha]\n",
    "    return \" \".join(set(tokens))  # Remove duplicates\n",
    "\n",
    "def fuzzy_match(keyword, patterns, fuzzy_threshold=82):\n",
    "    \"\"\"\n",
    "    Match a keyword to a list of patterns using both regex and fuzzy matching.\n",
    "    \"\"\"\n",
    "    for pattern in patterns:\n",
    "        # Check for exact regex match\n",
    "        if re.search(pattern, keyword.lower()):\n",
    "            return True\n",
    "        # Check for fuzzy match\n",
    "        if fuzz.partial_ratio(keyword.lower(), pattern.lower()) >= fuzzy_threshold:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def is_branded(keyword, branded_patterns, fuzzy_threshold=82):\n",
    "    return fuzzy_match(keyword, branded_patterns, fuzzy_threshold)\n",
    "\n",
    "def is_competitor(keyword, competitor_patterns, fuzzy_threshold=82):\n",
    "    return fuzzy_match(keyword, competitor_patterns, fuzzy_threshold)\n",
    "\n",
    "# Patterns for Each Country\n",
    "patterns = {\n",
    "    \"US\": {\n",
    "        \"branded\": [\n",
    "            r\"enzymedica\", r\"digest gold\", r\"acid soothe\", r\"glutenease\", r\"repair gold\",\n",
    "            r\"bean assist\", r\"lypo gold\", r\"digest spectrum\", r\"aqua biome\", r\"aquabiome omega 3\",\n",
    "            r\"magnesium mind\", r\"heart burn soothe\", r\"kids digest\", r\"lipo\", r\"magnesium motion\",\n",
    "            r\"berberine phytosome\", r\"candidase\", r\"digest basic\", r\"glutease\", r\"veggiegest\", r\"serra\",\n",
    "            r\"enzymedica\\s\\w+\", r\"dairy assist\", r\"dairy assit\"\n",
    "        ],\n",
    "        \"competitor\": [\n",
    "            r\"beano\", r\"zenwise\", r\"pure encapsulations\", r\"digestive advantage\", \n",
    "            r\"atrantil\", r\"thorne\", r\"now\", r\"enzyme science\", r\"metagenics\", r\"dr\\. formulated\", r\"candida\",\n",
    "            r\"zenwise\\s\\w+\", r\"beano\\s\\w+\"\n",
    "        ]\n",
    "    },\n",
    "    \"ES\": {\n",
    "    \"branded\": [\n",
    "        r\"enzymedica\", r\"oro digestivo\", r\"calma ácida\", r\"glutenease\", r\"oro reparador\",\n",
    "        r\"asistencia de frijoles\", r\"oro lipo\", r\"espectro digestivo\", r\"bioma acuático\", r\"aquabiome omega 3\",\n",
    "        r\"mente magnesio\", r\"alivio de ardor de estómago\", r\"niños digestivos\", r\"lipo\", r\"movimiento magnesio\",\n",
    "        r\"fitozoma de berberina\", r\"candidase\", r\"básico digestivo\", r\"glutease\", r\"veggiegest\", r\"serra\", r\"digest basic\",\n",
    "        r\"digest gold\", r\"digest complete\", r\"digest spectrum\", r\"lypo gold\", r\"beanassist\",\n",
    "        r\"enzymedica\\s\\w+\", r\"digestivo\\s\\w+\"\n",
    "    ],\n",
    "    \"competitor\": [\n",
    "        r\"aerored gases\", r\"aerored gases forte vientre plano\", r\"allergy calm boiron\", \n",
    "        r\"aquilea gases forte\", r\"aquilea gases vientre plano\", r\"creon 25000 pancreatina\", \n",
    "        r\"daofood plus\", r\"enzymatic therapy gluten defense\", r\"fodzyme\", r\"gluten cutter\", \n",
    "        r\"now super enzymes\", r\"super enzymes kal\", r\"vegan digestive enzymes solgar\", \n",
    "        r\"viridian digestive aid\", r\"now\"\n",
    "    ]\n",
    "},\n",
    "\"GE\": {\n",
    "    \"branded\": [\n",
    "        r\"enzymedica\", r\"digest gold\", r\"acid soothe\", r\"glutenease\", r\"repair gold\",\n",
    "        r\"bean assist\", r\"lypo gold\", r\"digest spectrum\", r\"aqua biome\", r\"aquabiome omega 3\",\n",
    "        r\"magnesium mind\", r\"heartburn relief\", r\"kids digest\", r\"lipo\", r\"magnesium motion\",\n",
    "        r\"candidase\", r\"digest basic\", r\"glutease\", r\"veggiegest\", r\"serra\",\n",
    "        r\"digest enzymes\", r\"digestive enzyme\", r\"verdauungsenzyme\",\n",
    "        r\"enzymedica\\s\\w+\", r\"digest\\s\\w+\", r\"lypo\\s\\w+\", r\"glutenease\\s\\w+\"\n",
    "    ],\n",
    "    \"competitor\": [\n",
    "        r\"beano\", r\"zenwise\", r\"pure encapsulations\", r\"digestive advantage\",\n",
    "        r\"atrantil\", r\"thorne\", r\"now\", r\"enzyme science\", r\"metagenics\", r\"dr\\. formulated\",\n",
    "        r\"simeticon\", r\"source naturals\", r\"life extensions\", r\"nortase enzyme\", \n",
    "        r\"papaya enzym kapseln\", r\"velgastin\", r\"her one digestion boost\", r\"fiber plus magnesium\",\n",
    "        r\"gluten block\", r\"gluten stop\", r\"gluten kapseln\", r\"gluten tabletten\", r\"rocky mountain enzym\",\n",
    "        r\"esn verdauungsenzyme\", r\"senna tabletten\", r\"essential enzymes\", r\"probiotic 200 billion\"\n",
    "    ]\n",
    "},\n",
    "\"IT\": {\n",
    "    \"branded\": [\n",
    "        r\"enzymedica\", r\"digest gold\", r\"gluten ease\", r\"lypo gold\", r\"glutenease\",\n",
    "        r\"digest spectrum\", r\"enzymedica digest\", r\"digest basic\", r\"enzymedica probiotic\",\n",
    "        r\"enzymedical9 glutenease\", r\"lypogold enzymedica\", r\"digest enzymes\", r\"enzimi digestivi enzymedica\",\n",
    "        r\"enzymedica\\s\\w+\", r\"digest\\s\\w+\", r\"lypo\\s\\w+\", r\"glutenease\\s\\w+\", r\"enzimi caseina\", r\"enzimi per lattosio e glutine\"\n",
    "    ],\n",
    "    \"competitor\": [\n",
    "        r\"beano\", r\"solgar\", r\"pure encapsulations\", r\"digestive advantage\", r\"helpzymes\", r\"erbenzym digest solgar\",\n",
    "        r\"herbenzym digest solgar\", r\"provida enzimi\", r\"integratori enzimi con amilasi lipasi proteasi\",\n",
    "        r\"prolife\", r\"nutraceutico enzimi digestivi\", r\"xls medical pro 7\", r\"enzimi digestivi ultra pure encapsulations\",\n",
    "        r\"farmaci per celiaci\", r\"ozempic per dimagrire\", r\"liraglutide per dimagrire\", r\"pancreatina\", r\"pasti sostitutivi dimagranti\",\n",
    "        r\"pasta senza glutine offerte\", r\"integratori brucia grassi addominali\", r\"prodotti gluten free e senza lattosio\", r\"gluten\"\n",
    "    ]\n",
    "},\n",
    "\"FR\": {\n",
    "    \"branded\": [\n",
    "        r\"enzymedica\", r\"digest gold\", r\"gluten ease\", r\"lypo gold\", r\"glutenease\",\n",
    "        r\"digest spectrum\", r\"kids digest\", r\"enzymes digestives bio\", r\"enzymes digestives gluten lactose\",\n",
    "        r\"digest basic\", r\"enzymes digestives lipase\", r\"digest enzymes\", r\"enzymes pour digérer la caséine\", r\"enzyme gluten lactose\", r\"enzymedica\\s\\w+\", r\"digest\\s\\w+\",\n",
    "        r\"lypo\\s\\w+\", r\"glutenease\\s\\w+\"\n",
    "    ],\n",
    "    \"competitor\": [\n",
    "         r\"beano\", r\"candida\", r\"candidase\", r\"nutra digest\", r\"nutri&co\", r\"fenouil gélules\",\n",
    "        r\"solgar\", r\"dr raphael perez\", r\"enzyme digestive vegan\", r\"enzyme digestive contre les gaz\",\n",
    "        r\"gluteostop\", r\"gluterase\", r\"enzymes alpha-galactosidase\", r\"enzymes betaine\",\n",
    "        r\"chewing pour estomac\", r\"pepsine\", r\"enzyme diet\", r\"enzyme digestive gluten\"\n",
    "    ]\n",
    "},\n",
    "}\n",
    "\n",
    "file_path = \"C:\\google_scraping\\Data\\Copy of Enzymedica - Keyword Clustering & Relevancy Definition.xlsx\"\n",
    "# Load all sheets from the Excel file\n",
    "all_sheets = pd.read_excel(file_path, sheet_name=None)\n",
    "\n",
    "# Define the number of clusters\n",
    "n_clusters = 3\n",
    "clustered_data = {}\n",
    "\n",
    "# Process each sheet\n",
    "for sheet_name, sheet_data in all_sheets.items():\n",
    "    sheet_data = pd.DataFrame(sheet_data)\n",
    "\n",
    "    if \"Keywords\" not in sheet_data.columns:\n",
    "        print(f\"Skipping sheet '{sheet_name}' - 'Keywords' column missing\")\n",
    "        continue\n",
    "\n",
    "    # Identify the market based on the sheet name\n",
    "    market = \"US\"  \n",
    "    if \"ES\" in sheet_name:\n",
    "        market = \"ES\"\n",
    "    elif \"GE\" in sheet_name:\n",
    "        market = \"GE\"\n",
    "    elif \"IT\" in sheet_name:\n",
    "        market = \"IT\"\n",
    "    elif \"FR\" in sheet_name:\n",
    "        market = \"FR\"\n",
    "\n",
    "    # Preprocess keywords for the identified market\n",
    "    keywords = sheet_data[\"Keywords\"].dropna().astype(str)\n",
    "    preprocessed_keywords = keywords.apply(lambda text: preprocess_text(text, market))\n",
    "\n",
    "    # Vectorize the preprocessed keywords using TF-IDF\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform(preprocessed_keywords)\n",
    "\n",
    "    # Apply KMeans clustering\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    kmeans.fit(X)\n",
    "\n",
    "    # Assign clusters and map them to categories using fuzzy matching\n",
    "    sheet_data[\"MARKET\"] = market\n",
    "    sheet_data[\"KW Type\"] = [\n",
    "        \"BR\" if is_branded(keyword, patterns[market][\"branded\"]) \n",
    "        else (\"CO\" if is_competitor(keyword, patterns[market][\"competitor\"]) \n",
    "              else \"GE\")\n",
    "        for keyword in keywords\n",
    "    ]\n",
    "\n",
    "    # Retain only relevant columns\n",
    "    relevant_columns = [\"MARKET\", \"Keywords\", \"KW Type\"]\n",
    "    sheet_data = sheet_data[relevant_columns]\n",
    "\n",
    "    # Store processed data\n",
    "    clustered_data[sheet_name] = sheet_data\n",
    "\n",
    "# Save all processed data to a consolidated Excel file\n",
    "output_path = \"clustered_keywords.xlsx\"\n",
    "with pd.ExcelWriter(output_path) as writer:\n",
    "    for sheet_name, data in clustered_data.items():\n",
    "        data.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "print(f\"Cleaned and clustered keywords saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
